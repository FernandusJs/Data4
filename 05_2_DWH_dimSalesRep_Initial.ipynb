{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Config stuff"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import random\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession, functions\n",
    "import ConnectionConfig as cc\n",
    "from delta import DeltaTable\n",
    "from pyspark.sql.functions import *"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-13T15:42:03.292477Z",
     "end_time": "2023-06-13T15:42:04.047379Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "<pyspark.sql.session.SparkSession at 0x2016f11fca0>",
      "text/html": "\n            <div>\n                <p><b>SparkSession - in-memory</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://AKDGPORT11191.admin.kdg.be:4040\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.1.1</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[*]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>DimDate</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        "
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from delta import configure_spark_with_delta_pip\n",
    "\n",
    "builder = SparkSession.builder \\\n",
    "    .appName(\"DimDate\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"4\") \\\n",
    "    .config(\"spark.driver.extraClassPath\", \":\".join(cc.jars)) \\\n",
    "    .master(\"local[*]\")\n",
    "builder = configure_spark_with_delta_pip(builder)\n",
    "spark = builder.getOrCreate()\n",
    "builder.getOrCreate()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Initial load\n",
    "We will create a slowly changing dimension type 2 called dimSalesRep based on a sourceTable in our operational database called dbo.salesrep. SCD2  tables demand extra care and  because we will store hirstorical values of the dimension with the help of ranges.\n",
    "This notebook will create the table and fill it with the initial data. A second notebook will be used for increments of new and changed data.\n",
    "\n",
    "This is an example of the expected output\n",
    "```\n",
    "+----------+-------------+-------------+-----------+-------------------+-------------------+--------------------+-------+\n",
    "|salesRepID|         name|       office| salesRepSK|          scd_start|            scd_end|                 md5|current|\n",
    "+----------+-------------+-------------+-----------+-------------------+-------------------+--------------------+-------+\n",
    "|         1|      Z. Jane|     New York|          0|1990-01-01 00:00:00|2100-12-12 00:00:00|303db545462092a92...|   true|\n",
    "|         2|   P. Chapman|       Berlin|          1|1990-01-01 00:00:00|2100-12-12 00:00:00|14b094c31bf9e4149...|   true|\n",
    "|         3|     T. Crane|     New York|          2|1990-01-01 00:00:00|2100-12-12 00:00:00|6c062f95defda9dc3...|   true|\n",
    "```\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- salesRepID: decimal(11,0) (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- office: string (nullable = true)\n",
      " |-- salesRepSK: long (nullable = false)\n",
      " |-- scd_start: timestamp (nullable = true)\n",
      " |-- scd_end: timestamp (nullable = true)\n",
      " |-- md5: string (nullable = true)\n",
      " |-- current: boolean (nullable = false)\n",
      "\n",
      "+----------+-------------+-------------+-----------+-------------------+-------------------+--------------------+-------+\n",
      "|salesRepID|         name|       office| salesRepSK|          scd_start|            scd_end|                 md5|current|\n",
      "+----------+-------------+-------------+-----------+-------------------+-------------------+--------------------+-------+\n",
      "|         1|      Z. Jane|      Chicago|          0|1990-01-01 00:00:00|2100-12-12 00:00:00|cbf61f481bec12d90...|   true|\n",
      "|         2|   P. Chapman|       Berlin|          1|1990-01-01 00:00:00|2100-12-12 00:00:00|14b094c31bf9e4149...|   true|\n",
      "|         3|     T. Crane|     New York|          2|1990-01-01 00:00:00|2100-12-12 00:00:00|6c062f95defda9dc3...|   true|\n",
      "|         4|    R. Geller|     New York|          3|1990-01-01 00:00:00|2100-12-12 00:00:00|6212c0ce01f144d66...|   true|\n",
      "|         5|      J.Mosby|       Berlin| 8589934592|1990-01-01 00:00:00|2100-12-12 00:00:00|fa85515824433037a...|   true|\n",
      "|         6|   B. Simpson|     New York| 8589934593|1990-01-01 00:00:00|2100-12-12 00:00:00|0ecb6ba5656492a5f...|   true|\n",
      "|         7|   B. Stinson|San Fransisco| 8589934594|1990-01-01 00:00:00|2100-12-12 00:00:00|e726b2d8dc0cf9a6f...|   true|\n",
      "|         8|L. Hofstadter|     Brussels| 8589934595|1990-01-01 00:00:00|2100-12-12 00:00:00|a2bbe52f8274b0f08...|   true|\n",
      "|         9|    S. Cooper|     Brussels| 8589934596|1990-01-01 00:00:00|2100-12-12 00:00:00|d85c73c9d03df0002...|   true|\n",
      "|        10| F. Underwood|     Brussels|17179869184|1990-01-01 00:00:00|2100-12-12 00:00:00|44cd1a6d596b05688...|   true|\n",
      "|        11|     W. White|     New York|17179869185|1990-01-01 00:00:00|2100-12-12 00:00:00|f9ea69ce2aa4482b4...|   true|\n",
      "|        12| T. Lannister|     New York|17179869186|1990-01-01 00:00:00|2100-12-12 00:00:00|3259a471f9816d7c3...|   true|\n",
      "|        13|    M. Rosske|       London|17179869187|1990-01-01 00:00:00|2100-12-12 00:00:00|c99e12e650c2aebc8...|   true|\n",
      "+----------+-------------+-------------+-----------+-------------------+-------------------+--------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cc.set_connection(\"mydb\")\n",
    "\n",
    "sales_df = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", cc.create_jdbc()) \\\n",
    "    .option(\"dbtable\", \"dbo.salesrep\") \\\n",
    "    .option(\"user\", cc.get_Property(\"username\")) \\\n",
    "    .option(\"password\", cc.get_Property(\"password\")) \\\n",
    "    .option(\"partitionColumn\", \"salesRepID\") \\\n",
    "    .option(\"numPartitions\", 4) \\\n",
    "    .option(\"lowerBound\", 0) \\\n",
    "    .option(\"upperBound\", 20) \\\n",
    "    .load() \\\n",
    "    .withColumn(\"salesRepSK\", monotonically_increasing_id()) \\\n",
    "    .withColumn(\"scd_start\", lit(\"1990-01-01\").cast(\"timestamp\")) \\\n",
    "    .withColumn(\"scd_end\", lit(\"2100-12-12\").cast(\"timestamp\")) \\\n",
    "    .withColumn(\"md5\", md5(concat( col('name'), col('office')))) \\\n",
    "    .withColumn(\"current\", lit(True))\n",
    "# first run\n",
    "\n",
    "\n",
    "sales_df.printSchema()\n",
    "sales_df.show()\n",
    "sales_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"dimSalesRep\")\n",
    "\n",
    "#spark.sql(\"ALTER TABLE dimSalesRep  ADD columns (salesRepSK long GENERATED ALWAYS AS IDENTITY (START WITH 0 INCREMENT BY 1)\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "* The function lit() is used when you want a fixed column value for every row. In this case scd_start, scd_end and current.\n",
    "* The function md5() performs a md5-hash function on the preferred columns. This is needed to detect changes in the incremental load notebook."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "spark.stop()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
